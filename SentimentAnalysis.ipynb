{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfTransformer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import *\n",
    "from textblob import Word\n",
    "import nltk\n",
    "#nltk.download('wordnet')\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>brand</th>\n",
       "      <th>categories</th>\n",
       "      <th>manufacturer</th>\n",
       "      <th>name</th>\n",
       "      <th>reviews_date</th>\n",
       "      <th>reviews_didPurchase</th>\n",
       "      <th>reviews_doRecommend</th>\n",
       "      <th>reviews_rating</th>\n",
       "      <th>reviews_text</th>\n",
       "      <th>reviews_title</th>\n",
       "      <th>reviews_userCity</th>\n",
       "      <th>reviews_userProvince</th>\n",
       "      <th>reviews_username</th>\n",
       "      <th>user_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AV13O1A8GV-KLJ3akUyj</td>\n",
       "      <td>Universal Music</td>\n",
       "      <td>Movies, Music &amp; Books,Music,R&amp;b,Movies &amp; TV,Mo...</td>\n",
       "      <td>Universal Music Group / Cash Money</td>\n",
       "      <td>Pink Friday: Roman Reloaded Re-Up (w/dvd)</td>\n",
       "      <td>2012-11-30T06:21:45.000Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>i love this album. it's very good. more to the...</td>\n",
       "      <td>Just Awesome</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>NaN</td>\n",
       "      <td>joshua</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AV14LG0R-jtxr-f38QfS</td>\n",
       "      <td>Lundberg</td>\n",
       "      <td>Food,Packaged Foods,Snacks,Crackers,Snacks, Co...</td>\n",
       "      <td>Lundberg</td>\n",
       "      <td>Lundberg Organic Cinnamon Toast Rice Cakes</td>\n",
       "      <td>2017-07-09T00:00:00.000Z</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>Good flavor. This review was collected as part...</td>\n",
       "      <td>Good</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dorothy w</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AV14LG0R-jtxr-f38QfS</td>\n",
       "      <td>Lundberg</td>\n",
       "      <td>Food,Packaged Foods,Snacks,Crackers,Snacks, Co...</td>\n",
       "      <td>Lundberg</td>\n",
       "      <td>Lundberg Organic Cinnamon Toast Rice Cakes</td>\n",
       "      <td>2017-07-09T00:00:00.000Z</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>Good flavor.</td>\n",
       "      <td>Good</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dorothy w</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AV16khLE-jtxr-f38VFn</td>\n",
       "      <td>K-Y</td>\n",
       "      <td>Personal Care,Medicine Cabinet,Lubricant/Sperm...</td>\n",
       "      <td>K-Y</td>\n",
       "      <td>K-Y Love Sensuality Pleasure Gel</td>\n",
       "      <td>2016-01-06T00:00:00.000Z</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>I read through the reviews on here before look...</td>\n",
       "      <td>Disappointed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>rebecca</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AV16khLE-jtxr-f38VFn</td>\n",
       "      <td>K-Y</td>\n",
       "      <td>Personal Care,Medicine Cabinet,Lubricant/Sperm...</td>\n",
       "      <td>K-Y</td>\n",
       "      <td>K-Y Love Sensuality Pleasure Gel</td>\n",
       "      <td>2016-12-21T00:00:00.000Z</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>My husband bought this gel for us. The gel cau...</td>\n",
       "      <td>Irritation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>walker557</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29995</th>\n",
       "      <td>AVpfW8y_LJeJML437ySW</td>\n",
       "      <td>L'oreal Paris</td>\n",
       "      <td>Beauty,Hair Care,Shampoo &amp; Conditioner,Holiday...</td>\n",
       "      <td>L'oreal Paris</td>\n",
       "      <td>L'or233al Paris Elvive Extraordinary Clay Reba...</td>\n",
       "      <td>2017-01-23T00:00:00.000Z</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "      <td>I got this conditioner with Influenster to try...</td>\n",
       "      <td>Softness!!</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>laurasnchz</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29996</th>\n",
       "      <td>AVpfW8y_LJeJML437ySW</td>\n",
       "      <td>L'oreal Paris</td>\n",
       "      <td>Beauty,Hair Care,Shampoo &amp; Conditioner,Holiday...</td>\n",
       "      <td>L'oreal Paris</td>\n",
       "      <td>L'or233al Paris Elvive Extraordinary Clay Reba...</td>\n",
       "      <td>2017-01-27T00:00:00.000Z</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "      <td>I love it , I received this for review purpose...</td>\n",
       "      <td>I love it</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>scarlepadilla</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29997</th>\n",
       "      <td>AVpfW8y_LJeJML437ySW</td>\n",
       "      <td>L'oreal Paris</td>\n",
       "      <td>Beauty,Hair Care,Shampoo &amp; Conditioner,Holiday...</td>\n",
       "      <td>L'oreal Paris</td>\n",
       "      <td>L'or233al Paris Elvive Extraordinary Clay Reba...</td>\n",
       "      <td>2017-01-21T00:00:00.000Z</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "      <td>First of all I love the smell of this product....</td>\n",
       "      <td>Hair is so smooth after use</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>liviasuexo</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29998</th>\n",
       "      <td>AVpfW8y_LJeJML437ySW</td>\n",
       "      <td>L'oreal Paris</td>\n",
       "      <td>Beauty,Hair Care,Shampoo &amp; Conditioner,Holiday...</td>\n",
       "      <td>L'oreal Paris</td>\n",
       "      <td>L'or233al Paris Elvive Extraordinary Clay Reba...</td>\n",
       "      <td>2017-01-11T00:00:00.000Z</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "      <td>I received this through Influenster and will n...</td>\n",
       "      <td>Perfect for my oily hair!</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ktreed95</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29999</th>\n",
       "      <td>AVpfW8y_LJeJML437ySW</td>\n",
       "      <td>L'oreal Paris</td>\n",
       "      <td>Beauty,Hair Care,Shampoo &amp; Conditioner,Holiday...</td>\n",
       "      <td>L'oreal Paris</td>\n",
       "      <td>L'or233al Paris Elvive Extraordinary Clay Reba...</td>\n",
       "      <td>2017-01-19T00:00:00.000Z</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "      <td>I received this product complimentary from inf...</td>\n",
       "      <td>Conditioned into healthy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>kcoopxoxo</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30000 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         id            brand  \\\n",
       "0      AV13O1A8GV-KLJ3akUyj  Universal Music   \n",
       "1      AV14LG0R-jtxr-f38QfS         Lundberg   \n",
       "2      AV14LG0R-jtxr-f38QfS         Lundberg   \n",
       "3      AV16khLE-jtxr-f38VFn              K-Y   \n",
       "4      AV16khLE-jtxr-f38VFn              K-Y   \n",
       "...                     ...              ...   \n",
       "29995  AVpfW8y_LJeJML437ySW    L'oreal Paris   \n",
       "29996  AVpfW8y_LJeJML437ySW    L'oreal Paris   \n",
       "29997  AVpfW8y_LJeJML437ySW    L'oreal Paris   \n",
       "29998  AVpfW8y_LJeJML437ySW    L'oreal Paris   \n",
       "29999  AVpfW8y_LJeJML437ySW    L'oreal Paris   \n",
       "\n",
       "                                              categories  \\\n",
       "0      Movies, Music & Books,Music,R&b,Movies & TV,Mo...   \n",
       "1      Food,Packaged Foods,Snacks,Crackers,Snacks, Co...   \n",
       "2      Food,Packaged Foods,Snacks,Crackers,Snacks, Co...   \n",
       "3      Personal Care,Medicine Cabinet,Lubricant/Sperm...   \n",
       "4      Personal Care,Medicine Cabinet,Lubricant/Sperm...   \n",
       "...                                                  ...   \n",
       "29995  Beauty,Hair Care,Shampoo & Conditioner,Holiday...   \n",
       "29996  Beauty,Hair Care,Shampoo & Conditioner,Holiday...   \n",
       "29997  Beauty,Hair Care,Shampoo & Conditioner,Holiday...   \n",
       "29998  Beauty,Hair Care,Shampoo & Conditioner,Holiday...   \n",
       "29999  Beauty,Hair Care,Shampoo & Conditioner,Holiday...   \n",
       "\n",
       "                             manufacturer  \\\n",
       "0      Universal Music Group / Cash Money   \n",
       "1                                Lundberg   \n",
       "2                                Lundberg   \n",
       "3                                     K-Y   \n",
       "4                                     K-Y   \n",
       "...                                   ...   \n",
       "29995                       L'oreal Paris   \n",
       "29996                       L'oreal Paris   \n",
       "29997                       L'oreal Paris   \n",
       "29998                       L'oreal Paris   \n",
       "29999                       L'oreal Paris   \n",
       "\n",
       "                                                    name  \\\n",
       "0              Pink Friday: Roman Reloaded Re-Up (w/dvd)   \n",
       "1             Lundberg Organic Cinnamon Toast Rice Cakes   \n",
       "2             Lundberg Organic Cinnamon Toast Rice Cakes   \n",
       "3                       K-Y Love Sensuality Pleasure Gel   \n",
       "4                       K-Y Love Sensuality Pleasure Gel   \n",
       "...                                                  ...   \n",
       "29995  L'or233al Paris Elvive Extraordinary Clay Reba...   \n",
       "29996  L'or233al Paris Elvive Extraordinary Clay Reba...   \n",
       "29997  L'or233al Paris Elvive Extraordinary Clay Reba...   \n",
       "29998  L'or233al Paris Elvive Extraordinary Clay Reba...   \n",
       "29999  L'or233al Paris Elvive Extraordinary Clay Reba...   \n",
       "\n",
       "                   reviews_date reviews_didPurchase reviews_doRecommend  \\\n",
       "0      2012-11-30T06:21:45.000Z                 NaN                 NaN   \n",
       "1      2017-07-09T00:00:00.000Z                True                 NaN   \n",
       "2      2017-07-09T00:00:00.000Z                True                 NaN   \n",
       "3      2016-01-06T00:00:00.000Z               False               False   \n",
       "4      2016-12-21T00:00:00.000Z               False               False   \n",
       "...                         ...                 ...                 ...   \n",
       "29995  2017-01-23T00:00:00.000Z               False                True   \n",
       "29996  2017-01-27T00:00:00.000Z               False                True   \n",
       "29997  2017-01-21T00:00:00.000Z               False                True   \n",
       "29998  2017-01-11T00:00:00.000Z               False                True   \n",
       "29999  2017-01-19T00:00:00.000Z               False                True   \n",
       "\n",
       "       reviews_rating                                       reviews_text  \\\n",
       "0                   5  i love this album. it's very good. more to the...   \n",
       "1                   5  Good flavor. This review was collected as part...   \n",
       "2                   5                                       Good flavor.   \n",
       "3                   1  I read through the reviews on here before look...   \n",
       "4                   1  My husband bought this gel for us. The gel cau...   \n",
       "...               ...                                                ...   \n",
       "29995               5  I got this conditioner with Influenster to try...   \n",
       "29996               5  I love it , I received this for review purpose...   \n",
       "29997               5  First of all I love the smell of this product....   \n",
       "29998               5  I received this through Influenster and will n...   \n",
       "29999               5  I received this product complimentary from inf...   \n",
       "\n",
       "                     reviews_title reviews_userCity reviews_userProvince  \\\n",
       "0                     Just Awesome      Los Angeles                  NaN   \n",
       "1                             Good              NaN                  NaN   \n",
       "2                             Good              NaN                  NaN   \n",
       "3                     Disappointed              NaN                  NaN   \n",
       "4                       Irritation              NaN                  NaN   \n",
       "...                            ...              ...                  ...   \n",
       "29995                   Softness!!              NaN                  NaN   \n",
       "29996                    I love it              NaN                  NaN   \n",
       "29997  Hair is so smooth after use              NaN                  NaN   \n",
       "29998    Perfect for my oily hair!              NaN                  NaN   \n",
       "29999     Conditioned into healthy              NaN                  NaN   \n",
       "\n",
       "      reviews_username user_sentiment  \n",
       "0               joshua       Positive  \n",
       "1            dorothy w       Positive  \n",
       "2            dorothy w       Positive  \n",
       "3              rebecca       Negative  \n",
       "4            walker557       Negative  \n",
       "...                ...            ...  \n",
       "29995       laurasnchz       Positive  \n",
       "29996    scarlepadilla       Positive  \n",
       "29997       liviasuexo       Positive  \n",
       "29998         ktreed95       Positive  \n",
       "29999        kcoopxoxo       Positive  \n",
       "\n",
       "[30000 rows x 15 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset\n",
    "Review_data=pd.read_csv(\"sample30.csv\")\n",
    "Review_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                      30000\n",
       "brand                   30000\n",
       "categories              30000\n",
       "manufacturer            29859\n",
       "name                    30000\n",
       "reviews_date            29954\n",
       "reviews_didPurchase     15932\n",
       "reviews_doRecommend     27430\n",
       "reviews_rating          30000\n",
       "reviews_text            30000\n",
       "reviews_title           29810\n",
       "reviews_userCity         1929\n",
       "reviews_userProvince      170\n",
       "reviews_username        29937\n",
       "user_sentiment          29999\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets verify the Blank values\n",
    "Review_data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews_text</th>\n",
       "      <th>user_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i love this album. it's very good. more to the...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Good flavor. This review was collected as part...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Good flavor.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I read through the reviews on here before look...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>My husband bought this gel for us. The gel cau...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29995</th>\n",
       "      <td>I got this conditioner with Influenster to try...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29996</th>\n",
       "      <td>I love it , I received this for review purpose...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29997</th>\n",
       "      <td>First of all I love the smell of this product....</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29998</th>\n",
       "      <td>I received this through Influenster and will n...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29999</th>\n",
       "      <td>I received this product complimentary from inf...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            reviews_text  user_sentiment\n",
       "0      i love this album. it's very good. more to the...               1\n",
       "1      Good flavor. This review was collected as part...               1\n",
       "2                                           Good flavor.               1\n",
       "3      I read through the reviews on here before look...               0\n",
       "4      My husband bought this gel for us. The gel cau...               0\n",
       "...                                                  ...             ...\n",
       "29995  I got this conditioner with Influenster to try...               1\n",
       "29996  I love it , I received this for review purpose...               1\n",
       "29997  First of all I love the smell of this product....               1\n",
       "29998  I received this through Influenster and will n...               1\n",
       "29999  I received this product complimentary from inf...               1\n",
       "\n",
       "[30000 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Update the sentiment values {Positive:1, Negative:0}\n",
    "Review_data['user_sentiment']=Review_data['user_sentiment'].map({'Negative':0, 'Positive':1,})\n",
    "# Because most of the reviews are positive, update the missing sentiment value to positive\n",
    "Review_data['user_sentiment'] = Review_data.user_sentiment.fillna(1)\n",
    "Review_data['user_sentiment']= Review_data['user_sentiment'].astype('int')\n",
    "Review_data=Review_data[['reviews_text','user_sentiment']]\n",
    "Review_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='user_sentiment', ylabel='count'>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Lets check the distribution of Positive and negative sentiments\n",
    "sns.countplot(x='user_sentiment', data=Review_data)\n",
    "\n",
    "# This chart shows that there is a huge difference between positive and negative datas count. So the data is balanced at later point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define method for text filering\n",
    "\n",
    "def text_process(text):\n",
    "    # Remove digits\n",
    "    text = re.sub(r'[0-9]', '', text)\n",
    "    # Remove all the special characters\n",
    "    text = re.sub(r'\\W', ' ', text)\n",
    "    # remove all single characters\n",
    "    text = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', text)\n",
    "    # Remove single characters from the start\n",
    "    text = re.sub(r'\\^[a-zA-Z]\\s+', ' ', text) \n",
    "    # Substituting multiple spaces with single space\n",
    "    text= re.sub(r'\\s+', ' ', text, flags=re.I)\n",
    "    # Removing prefixed 'b'\n",
    "    text = re.sub(r'^b\\s+', '', text)\n",
    "    text = text.lower()\n",
    "    text=lemmatizer.lemmatize(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets just use the user review's comment only for sentiment analysis \n",
    "X = Review_data['reviews_text']\n",
    "Y = Review_data['user_sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        i love this album it very good more to the hip...\n",
       "1        good flavor this review wa collected a part of...\n",
       "2                                              good flavor\n",
       "3        i read through the review on here before looki...\n",
       "4        my husband bought this gel for u the gel cause...\n",
       "                               ...                        \n",
       "29995    i got this conditioner with influenster to try...\n",
       "29996    i love it received this for review purpose fro...\n",
       "29997    first of all love the smell of this product af...\n",
       "29998    i received this through influenster and will n...\n",
       "29999    i received this product complimentary from inf...\n",
       "Name: reviews_text, Length: 30000, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = X.apply(lambda x: text_process(x))\n",
    "X = X.apply(lambda x: ' '.join([Word(word).lemmatize() for word in x.split()]))\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define TfidfVectorizer\n",
    "tfidf = TfidfVectorizer(max_features=1500, lowercase=True, analyzer='word', stop_words= 'english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for feature extraction and use different machine learning models on those features\n",
    "\n",
    "def model_fit(X, y, feature_model,ml_model,coef_show=1):\n",
    "    \n",
    "    X_features = feature_model.fit_transform(X)\n",
    "    print('# features: {}'.format(X_features.shape[1]))\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_features, y, test_size = 0.2, random_state=45)\n",
    "    clf = ml_model.fit(X_train, y_train)\n",
    "    clf_pred = clf.predict(X_test)\n",
    "    accuracy = clf.score(X_test, y_test)\n",
    "    model_performance = classification_report(y_test, clf_pred)\n",
    "    print ('accuracy of the model: ', accuracy)\n",
    "    print('')\n",
    "    print(model_performance)\n",
    "    \n",
    "    if coef_show == 1: \n",
    "        w = feature_model.get_feature_names()\n",
    "        coef = clf.coef_.tolist()[0]\n",
    "        coeff_df = pd.DataFrame({'Word' : w, 'Coefficient' : coef})\n",
    "        coeff_df = coeff_df.sort_values(['Coefficient', 'Word'], ascending=[0, 1])\n",
    "        print('')\n",
    "        print('Top 10 positive features (variables)')\n",
    "        print(coeff_df.head(20).to_string(index=False))\n",
    "        print('')\n",
    "        print('Top 10 negative features (variables)')        \n",
    "        print(coeff_df.tail(20).to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# features: 1500\n",
      "accuracy of the model:  0.9206666666666666\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.35      0.51       699\n",
      "           1       0.92      1.00      0.96      5301\n",
      "\n",
      "    accuracy                           0.92      6000\n",
      "   macro avg       0.92      0.67      0.73      6000\n",
      "weighted avg       0.92      0.92      0.90      6000\n",
      "\n",
      "\n",
      "Top 10 positive features (variables)\n",
      "      Word  Coefficient\n",
      "     great    13.441715\n",
      "      love     9.009180\n",
      "      best     8.206093\n",
      "      easy     7.823733\n",
      "      good     7.548924\n",
      "     clean     6.730321\n",
      "     loved     5.789734\n",
      "    better     5.534399\n",
      "      nice     5.247802\n",
      " excellent     5.039316\n",
      "   perfect     4.964008\n",
      "   amazing     4.598320\n",
      "   awesome     4.528715\n",
      "   enjoyed     4.444107\n",
      "  favorite     4.149565\n",
      "      free     4.019181\n",
      " wonderful     3.785794\n",
      "    really     3.609970\n",
      "     fresh     3.488662\n",
      "     handy     3.457102\n",
      "\n",
      "Top 10 negative features (variables)\n",
      "         Word  Coefficient\n",
      "          son    -1.825705\n",
      "         poor    -1.898829\n",
      "         base    -1.921117\n",
      "       boring    -2.085675\n",
      "        crazy    -2.433385\n",
      "     resident    -2.441705\n",
      "          sad    -2.494070\n",
      "         cold    -2.598591\n",
      "        worst    -2.780284\n",
      "         hate    -2.823527\n",
      "        wrong    -3.093705\n",
      "          bad    -3.593913\n",
      "        nasty    -3.851286\n",
      "        dirty    -3.864987\n",
      "         evil    -3.912869\n",
      "     horrible    -4.398211\n",
      "        awful    -4.442372\n",
      "         sick    -4.563042\n",
      " disappointed    -4.719820\n",
      "     terrible    -5.267039\n"
     ]
    }
   ],
   "source": [
    "# Fit model using logistic regression\n",
    "\n",
    "model_fit(X, Y, tfidf,LogisticRegression(),coef_show=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the tfidf vectorizer reference for future usase.\n",
    "pickle.dump(tfidf, open('tfidf.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    26633\n",
       "0     3367\n",
       "Name: user_sentiment, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets verify the data balancing\n",
    "Y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    21332\n",
       "0    21332\n",
       "Name: user_sentiment, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_features=tfidf.fit_transform(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_features, Y, test_size = 0.2, random_state=45)\n",
    "\n",
    "# Because there is a huge gap between positive and Negative sentiments, lets balance the data first \n",
    "sm = SMOTE()\n",
    "X_train_smote, y_train_smote = sm.fit_sample(X_train, y_train)\n",
    "X_test_smote, y_test_smote = sm.fit_sample(X_test, y_test)\n",
    "y_train_smote.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    5301\n",
       "0    5301\n",
       "Name: user_sentiment, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_smote.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to git the model for bslsnced data\n",
    "def class_balanced_model_fit(X_train_smote, y_train_smote, X_test_smote, y_test_smote, ml_model,filename):\n",
    "    \n",
    "    clf = ml_model.fit(X_train_smote, y_train_smote)\n",
    "    clf_pred = clf.predict(X_test_smote)\n",
    "    accuracy = clf.score(X_test_smote, y_test_smote)\n",
    "    model_performance = classification_report(y_test_smote, clf_pred)\n",
    "    validation_pred_proba_grad = clf.predict_proba(X_test_smote)\n",
    "    roc_auc = roc_auc_score(y_test_smote, validation_pred_proba_grad[:,1])\n",
    "    pickle.dump(clf, open(filename, 'wb'))\n",
    "    print ('accuracy of the model: ', accuracy)\n",
    "    print('')\n",
    "    print(model_performance)\n",
    "    print('')\n",
    "    print('ROC_AUC score: ', roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of the model:  0.9316166760988492\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.94      0.93      5301\n",
      "           1       0.94      0.93      0.93      5301\n",
      "\n",
      "    accuracy                           0.93     10602\n",
      "   macro avg       0.93      0.93      0.93     10602\n",
      "weighted avg       0.93      0.93      0.93     10602\n",
      "\n",
      "\n",
      "ROC_AUC score:  0.9808938072178598\n"
     ]
    }
   ],
   "source": [
    "# Using logistic regression\n",
    "class_balanced_model_fit(X_train_smote, y_train_smote, X_test_smote, y_test_smote, LogisticRegression(),'lgregression.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of the model:  0.8045651763818148\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.75      0.79      5301\n",
      "           1       0.78      0.86      0.81      5301\n",
      "\n",
      "    accuracy                           0.80     10602\n",
      "   macro avg       0.81      0.80      0.80     10602\n",
      "weighted avg       0.81      0.80      0.80     10602\n",
      "\n",
      "\n",
      "ROC_AUC score:  0.8889171267191047\n"
     ]
    }
   ],
   "source": [
    "# Using Naivebyes (Using Multinomial)\n",
    "class_balanced_model_fit(X_train_smote, y_train_smote, X_test_smote, y_test_smote, MultinomialNB(),'nvb_multinomial.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of the model:  0.822014714204867\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.78      0.82      5301\n",
      "           1       0.80      0.86      0.83      5301\n",
      "\n",
      "    accuracy                           0.82     10602\n",
      "   macro avg       0.82      0.82      0.82     10602\n",
      "weighted avg       0.82      0.82      0.82     10602\n",
      "\n",
      "\n",
      "ROC_AUC score:  0.8920009397663772\n"
     ]
    }
   ],
   "source": [
    "# Using Nsivebyes (Bernoulli)\n",
    "class_balanced_model_fit(X_train_smote, y_train_smote, X_test_smote, y_test_smote, BernoulliNB(),'nvb_bernoulli.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of the model:  0.899641577060932\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.84      0.89      5301\n",
      "           1       0.86      0.96      0.91      5301\n",
      "\n",
      "    accuracy                           0.90     10602\n",
      "   macro avg       0.91      0.90      0.90     10602\n",
      "weighted avg       0.91      0.90      0.90     10602\n",
      "\n",
      "\n",
      "ROC_AUC score:  0.9720112925698636\n"
     ]
    }
   ],
   "source": [
    "# Using RandomForest\n",
    "classifier = RandomForestClassifier(n_estimators=100, random_state=0)\n",
    "class_balanced_model_fit(X_train_smote, y_train_smote, X_test_smote, y_test_smote, classifier,'randomforest.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\madsingh\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:01:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model:  0.9168081494057725\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.91      0.92      5301\n",
      "           1       0.91      0.92      0.92      5301\n",
      "\n",
      "    accuracy                           0.92     10602\n",
      "   macro avg       0.92      0.92      0.92     10602\n",
      "weighted avg       0.92      0.92      0.92     10602\n",
      "\n",
      "\n",
      "ROC_AUC score:  0.971923073816108\n"
     ]
    }
   ],
   "source": [
    "# Using XGBoot\n",
    "class_balanced_model_fit(X_train_smote, y_train_smote, X_test_smote, y_test_smote, XGBClassifier(),'xgboost.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Conclusion Now because the accuracy, ROC_AUC and other parameters score are better for Logistic regression than other Algorithms,So we would be using Logistic regression model for future usage."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
